{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition â€“ Unlock Your Application With Your Face!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1 - Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './faces/user/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'face'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e77ff165c0a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# Initialize facial recognizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLBPHFaceRecognizer_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'face'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Get the training data we previously made\n",
    "data_path = './faces/user/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "# Initialize facial recognizer\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "\n",
    "# Let's train our model \n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained sucessefully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Run Our Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results = model.predict(face)\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        if confidence > 75:\n",
    "            cv2.putText(image, \"Unlocked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "        else:\n",
    "            cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "imshow() missing required argument 'winname' (pos 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e7b208bf19ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: imshow() missing required argument 'winname' (pos 1)"
     ]
    }
   ],
   "source": [
    "cv2.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "lst=[]\n",
    "start_time=time.time()\n",
    "elapsed_time=time.time()\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        start_time = time.time()\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(time.clock()), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print(\"Face not found\")\n",
    "        elapsed_time = time.time() - start_time\n",
    "        lst.append(elapsed_time)\n",
    "        seconds=0\n",
    "        time.sleep(1)\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        \n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03690147399902344, 1.0522046089172363, 0.05485343933105469]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(lst,bins=20,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'datetime.datetime' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ccbdafdd80a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'datetime.datetime' and 'float'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.now()-time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.000815391540527\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "time.sleep(5)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
